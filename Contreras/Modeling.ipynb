{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f2f663",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prepare'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dc/8rtfvpyj2mb6mqbnfkf5dl400000gn/T/ipykernel_28440/1105329763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prepare'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "import pandas as pd\n",
    "#import bamboolib as bam\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import acquire\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import f_regression \n",
    "\n",
    "#statistical tests\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import prepare\n",
    "import plotly.express as px\n",
    "\n",
    "#imports to show interactive visuals on github\n",
    "import plotly.io as pio\n",
    "pio.renderers\n",
    "\n",
    "import model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347d36f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9c059",
   "metadata": {},
   "source": [
    "# `Acquire` Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b26fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_fifa_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8192d4c6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01998d31",
   "metadata": {},
   "source": [
    "# Import [Prepare.py](https://github.com/Jules-Ray-Kayla-Bert-Capstone-FiFA/fifa/blob/main/prepare.py) File.\n",
    "`Summary:`\n",
    "    This file was created with the purpose of cleaning, encoding, scaling, dropping, and adding collumns to our existing data. It is necessary to complete this preperation step before we start exploring and modeling our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining df as our imported prepped data.\n",
    "df = prepare.prepped_data(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wage_eur.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['overall','potential'] \n",
    "def handle_outliers(df, cols, k):\n",
    "    \"\"\"this will eliminate most outliers, use a 1.5 k value if unsure because it is the most common, make sure to define cols value as the features\n",
    "    you want the outliers to be handled. this should be done before running the function and outiside of it\"\"\"\n",
    "\n",
    "    \n",
    "    # Create placeholder dictionary for each columns bounds\n",
    "    bounds_dict = {}\n",
    "   \n",
    "    for col in cols:\n",
    "        # get necessary iqr values\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        upper_bound =  q3 + k * iqr\n",
    "        lower_bound =  q1 - k * iqr\n",
    "\n",
    "        #store values in a dictionary referencable by the column name\n",
    "        #and specific bound\n",
    "        bounds_dict[col] = {}\n",
    "        bounds_dict[col]['upper_bound'] = upper_bound\n",
    "        bounds_dict[col]['lower_bound'] = lower_bound\n",
    "\n",
    "    for col in cols:\n",
    "        #retrieve bounds\n",
    "        col_upper_bound = bounds_dict[col]['upper_bound']\n",
    "        col_lower_bound = bounds_dict[col]['lower_bound']\n",
    "\n",
    "        #remove rows with an outlier in that column\n",
    "    df = df[(df[col] < col_upper_bound) & (df[col] > col_lower_bound)]\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = handle_outliers(df,cols,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ea4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030bf96b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.wage_eur.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e37e21b",
   "metadata": {},
   "source": [
    "# `Explore`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a8dc8",
   "metadata": {},
   "source": [
    "## Importing split function to start our exploring on our train data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef50b8",
   "metadata": {},
   "source": [
    "***\n",
    "# Relationship to Wage_euro Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55ff57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "train.corr()['wage_eur'].sort_values(ascending=False).plot(kind='barh', color='orange')\n",
    "plt.title('Relationship with wages')\n",
    "plt.xlabel('Relationship')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193d591",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features_cor =  train.corr()['wage_eur'].sort_values(ascending=False)\n",
    "features_cor = pd.DataFrame(features_cor)\n",
    "features_cor.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df09add",
   "metadata": {},
   "source": [
    "`Takeaways:` \n",
    "For this Exploration section I wil be focusing on the skills that are under or equal to 70 percent of correlation and greater then 48 percent. \n",
    "The list below will be the skills and stats that I will be focusing on.\n",
    "\n",
    "- overall\n",
    "- passing\n",
    "- ball_control\n",
    "- short_passing\n",
    "- reactions\n",
    "- potential\n",
    "- dribbling\n",
    "- vision\n",
    "- skill_dribbling\n",
    "- league_yr_sum\n",
    "- long_passing\n",
    "- shooting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e98e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying mvp columns\n",
    "mvp = ['international_reputation','overall','reactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[mvp]\n",
    "y_train = train[['wage_eur']]\n",
    "\n",
    "X_validate = validate[mvp]\n",
    "y_validate = validate[['wage_eur']]\n",
    "\n",
    "X_test = test[mvp]\n",
    "y_test = test[['wage_eur']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471648d",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = RobustScaler()\n",
    "## Note that we only call .fit with the training data,\n",
    "## but we use .transform to apply the scaling to all the data splits.\n",
    "#scaler.fit(X_train)\n",
    "#X_train_scaled = scaler.transform(X_train)\n",
    "#X_validate_scaled = scaler.transform(X_validate)\n",
    "#X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ced52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler, X_train_scaled, X_validate_scaled, X_test_scaled = scale_data(X_train, X_validate, X_test, return_scaler=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ca93a",
   "metadata": {},
   "source": [
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4316bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'wage_eur'\n",
    "#create baseline\n",
    "metric_df, rmse_mean_train, rmse_mean_validate, rmse_median_train, rmse_median_validate, r2_baseline = model.create_baseline(y_train, y_validate, target)\n",
    "#Linear Regression model\n",
    "rmse_lm_train, rmse_lm_validate, r2_lm_value = model.create_model(LinearRegression(normalize = True), X_train,\\\n",
    "                                                                  X_validate, y_train, y_validate, 'wage_eur')\n",
    "#Lasso + Lars model\n",
    "rmse_lars_train, rmse_lars_validate, r2_lars_value = model.create_model(LassoLars(alpha = 1.0), X_train,\\\n",
    "                                                            X_validate, y_train, y_validate, 'wage_eur')\n",
    "#Tweedie Regressor model\n",
    "rmse_glm_train, rmse_glm_validate, r2_glm_value = model.create_model(TweedieRegressor(power = 1, alpha = 0.00),\\\n",
    "                                                            X_train, X_validate, y_train, y_validate, 'wage_eur')\n",
    "print(metric_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc7c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23590ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "= model.create_model(LinearRegression(normalize = True), X_train,X_validate, y_train, y_validate, 'wage_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_model(LinearRegression(normalize = True), X_train,X_validate, y_train, y_validate, 'wage_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d28375",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_model(LassoLars(alpha = 1.0), X_train,X_validate, y_train, y_validate, 'wage_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_model(TweedieRegressor(power = 1, alpha = 0.00),X_train, X_validate, y_train, y_validate, 'wage_eur')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf5443",
   "metadata": {},
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "y = pd.DataFrame(y_train.wage_eur)\n",
    "X = pd.DataFrame(X_train_scaled)\n",
    "# assuming X and y are already defined\n",
    "model = LinearRegression().fit(X, y)\n",
    "train['yhat'] = model.predict(X)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf20aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train[['potential', 'reactions', 'vision', 'short_passing','long_passing',\n",
    "       'ball_control','wage_eur','yhat']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7313bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a baseline from the mean of the target variable\n",
    "baseline = y.mean()\n",
    "df['baseline'] = y.wage_eur.mean()\n",
    "# turning baseline to int from float\n",
    "df.baseline = df.baseline.astype(int)\n",
    "# residual = actual - predicted\n",
    "df['residual'] = df.wage_eur - df.yhat\n",
    "df['baseline_residual'] = df.wage_eur - df.baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ef44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['residual^2'] = df.residual**2\n",
    "df['baseline_residual^2'] = df.baseline_residual**2\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7be17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = SSE/len(df)\n",
    "MSE_baseline = SSE_baseline/len(df)\n",
    "\n",
    "print(\"MSE = \", \"{:.1f}\".format(MSE))\n",
    "print(\"MSE baseline = \", \"{:.1f}\".format(MSE_baseline))\n",
    "\n",
    "if MSE < MSE_baseline:\n",
    "    print('MSE is better than baseline')\n",
    "else:\n",
    "    print('baseline is better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0574d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "RMSE = sqrt(MSE)\n",
    "RMSE_baseline =  sqrt(MSE_baseline)\n",
    "\n",
    "if RMSE < RMSE_baseline:\n",
    "    print('RMSE is better than baseline')\n",
    "else:\n",
    "    print('baseline is better')\n",
    "    \n",
    "print(\"RMSE = \", \"{:.1f}\".format(RMSE))\n",
    "print(\"RMSE baseline = \", \"{:.1f}\".format(RMSE_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1bbe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SSE < SSE_baseline:\n",
    "    print('OLS regression model performs better than the baseline')\n",
    "else:\n",
    "    print('OLS regression model performs worse than the baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.metrics.explained_variance_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "evs = explained_variance_score(df.wage_eur, df.yhat)\n",
    "print('Explained Variance = ', round(evs,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate R2 the easy way:\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(df.wage_eur, df.yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X2 = sm.add_constant(df.potential)\n",
    "est = sm.OLS(df.wage_eur, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(actual, predicted):\n",
    "    return actual - predicted\n",
    "\n",
    "#sum of squared errors (SSE)\n",
    "def sse(actual, predicted):\n",
    "    return (residuals(actual, predicted) **2).sum()\n",
    "\n",
    "#explained sum of squares (ESS)\n",
    "def ess(actual, predicted):\n",
    "    return ((predicted - actual.mean()) ** 2).sum()\n",
    "\n",
    "#total sum of squares (TSS)\n",
    "def tss(actual):\n",
    "    return ((actual - actual.mean()) ** 2).sum()\n",
    "\n",
    "#mean squared error (MSE)\n",
    "def mse(actual, predicted):\n",
    "    n = actual.shape[0]\n",
    "    return sse(actual, predicted) / n\n",
    "\n",
    "#root mean squared error (RMSE)\n",
    "def rmse(actual, predicted):\n",
    "    return math.sqrt(mse(actual, predicted))\n",
    "\n",
    "# returns r2 scor\n",
    "def r2_score(actual, predicted):\n",
    "    return ess(actual, predicted) / tss(actual)\n",
    "\n",
    "def regression_errors(actual, predicted):\n",
    "    return pd.Series({\n",
    "                        'SSE': sse(actual, predicted),\n",
    "                        'ESS': ess(actual, predicted),\n",
    "                        'TSS': tss(actual),\n",
    "                        'MSE': mse(actual, predicted),\n",
    "                        'RMSE': rmse(actual, predicted),\n",
    "                        })\n",
    "\n",
    "def baseline_mean_errors(actual):\n",
    "    predicted = actual.mean()\n",
    "    return {\n",
    "             'SSE': sse(actual, predicted),\n",
    "             'MSE': mse(actual, predicted),\n",
    "             'RMSE': rmse(actual, predicted),\n",
    "            }\n",
    "\n",
    "def better_than_baseline(actual, predicted):\n",
    "    rmse_baseline = rmse(actual, actual.mean())\n",
    "    rmse_model = rmse(actual, predicted)\n",
    "    return rmse_model < rmse_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = y_train.wage_eur\n",
    "predicted = df.yhat\n",
    "residuals = actual - predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_vs_predicted():\n",
    "    # plot to visualize actual vs predicted. \n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.hist(y_validate.wage_eur, color='blue', alpha=.5, label=\"Actual Final wage_eur\")\n",
    "    plt.hist(y_validate.wage_eur_pred_lm, color='red', alpha=.5, label=\"Model: LinearRegression\")\n",
    "    plt.hist(y_validate.wage_eur_pred_glm, color='yellow', alpha=.5, label=\"Model: TweedieRegressor\")\n",
    "    plt.hist(y_validate.wage_eur_pred_lm2, color='green', alpha=.5, label=\"Model 2nd degree Polynomial\")\n",
    "    plt.xlabel(\"Final wage(eur)\")\n",
    "    plt.ylabel(\"predicted wage_eur\")\n",
    "    plt.title(\"Comparing the Distribution of Actual wage_eur to Distributions of Predicted wage_eur for the Top Models\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "actual_vs_predicted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da25db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bcacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame(data=[{\n",
    "    'model': 'mean_baseline', \n",
    "    'RMSE_validate': rmse_validate,\n",
    "        'r^2_validate': explained_variance_score(y_validate.wage_eur, y_validate.wage_eur_pred_mean)}])\n",
    "metric_df = metric_df.append({\n",
    "    'model': 'OLS Regressor', \n",
    "    'RMSE_validate': rmse_validate_lm,\n",
    "    'r^2_validate': explained_variance_score(y_validate.wage_eur, y_validate.wage_eur_pred_lm)}, ignore_index=True)\n",
    "metric_df = metric_df.append({\n",
    "    'model': 'Lasso alpha 1', \n",
    "    'RMSE_validate': rmse_validate_lars,\n",
    "    'r^2_validate': explained_variance_score(y_validate.wage_eur, y_validate.wage_eur_pred_lars)}, ignore_index=True)\n",
    "metric_df = metric_df.append({\n",
    "    'model': 'GLM (tweedie)', \n",
    "    'RMSE_validate': rmse_validate_glm,\n",
    "    'r^2_validate': explained_variance_score(y_validate.wage_eur, y_validate.wage_eur_pred_glm)}, ignore_index=True)\n",
    "metric_df = metric_df.append({\n",
    "    'model': 'Poly', \n",
    "    'RMSE_validate': rmse_validate_lm2,\n",
    "    'r^2_validate': explained_variance_score(y_validate.wage_eur, y_validate.wage_eur_pred_lm2)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79814d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01fa194",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "# predict on test\n",
    "y_test['wage_eur_pred_LINEAR'] = lm.predict(X_test_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_test_lm = mean_squared_error(y_test.wage_eur, y_test.wage_eur_pred_LINEAR)**(1/2)\n",
    "\n",
    "print(\"RMSE for OLS Model using LinearRegression\\nOut-of-Sample Performance: \", rmse_test_lm)\n",
    "\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "# predict on test\n",
    "y_test['wage_eur_pred_LASSO'] = lars.predict(X_test_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_test_lars = mean_squared_error(y_test.wage_eur, y_test.wage_eur_pred_LASSO)**(1/2)\n",
    "\n",
    "print(\"RMSE for OLS Model using Lasso\\nOut-of-Sample Performance: \", rmse_test_lars)\n",
    "\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "#predict on test\n",
    "y_test['pred_Poly'] = lm2.predict(X_test_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_test = mean_squared_error(y_test.wage_eur, y_test.pred_Poly)**(0.5)\n",
    "\n",
    "print(f\"\"\"\n",
    "RMSE for Polynomial Regressor, degrees=2:\n",
    "Test/Out-of-Sample Performance: {rmse_test}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "#predict on test\n",
    "y_test['wage_eur_pred_glm'] = glm.predict(X_test_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_test = mean_squared_error(y_test.wage_eur, y_test.wage_eur_pred_glm)**(1/2)\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_glm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b363bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7447cfb0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
